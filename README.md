# ğŸ“š DSDE 2025 â€” Research Insights Platform  
A full-stack system for **bulk Scopus ingestion**, **analytics**, and **AI-powered semantic search** using **PostgreSQL + pgvector**, **Dash**, and an **Ollama-based RAG engine**.

---

# ğŸš€ Features

### âœ” Bulk Scopus JSON â†’ PostgreSQL ingestion  
- Sequential batching (safe re-runs, rollback on batch failure)  
- Inserts authors, affiliations, keywords, subjects, funding, references  
- Generates embeddings (768-dim vectors) and stores them in `paper_embeddings`

### âœ” PostgreSQL + pgvector  
- Fast semantic search via `<=>` vector distance  
- Optimized schema (indexes, views, normalization)

### âœ” Dash Web Application (`app/`)
- Papers explorer  
- Author analytics  
- Affiliations explorer  
- Paper info viewer  
- **Chat-based RAG research assistant**

### âœ” RAG Engine (`app/lib/rag_engine.py`)
- Embedding generation using **Ollama â†’ nomic-embed-text**  
- Context retrieval (pgvector)  
- Answer generation using local LLM (Qwen, Llama, etc.)  
- Returns citations and relevance scores  

---

# ğŸ—‚ Project Structure

```text
smartwhatt-dsde-2025-project/
â”‚
â”œâ”€â”€ initialize_table.sql
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ main.py
â”‚
â”œâ”€â”€ processing/
â”‚   â”œâ”€â”€ json_to_csv.py
â”‚   â”œâ”€â”€ load_csv_to_db.py
â”‚   â”œâ”€â”€ calculate_embedding_to_db.py
â”‚   â”œâ”€â”€ verify_db.py
â”‚   â””â”€â”€ lib/
â”‚       â”œâ”€â”€ embedder.py
â”‚       â”œâ”€â”€ csv_exporter.py
â”‚       â””â”€â”€ csv_to_db_loader.py
â”‚
â””â”€â”€ app/
    â”œâ”€â”€ main.py
    â”œâ”€â”€ database.py
    â”œâ”€â”€ lib/
    â”‚   â””â”€â”€ rag_engine.py
    â””â”€â”€ pages/
        â”œâ”€â”€ home.py
        â”œâ”€â”€ chat.py
        â”œâ”€â”€ papers.py
        â”œâ”€â”€ paper_info.py
        â”œâ”€â”€ author_profile.py
        â”œâ”€â”€ affiliations.py
        â”œâ”€â”€ faculty.py
        â””â”€â”€ test.py
```

# âš™ï¸ Full Setup Guide

Below is the complete setup process, including database, Ollama, and processing pipeline.

## 1ï¸âƒ£ Install Required Software

```bash
# Python (3.11 recommended)
sudo apt install python3 python3-pip

# PostgreSQL
sudo apt install postgresql postgresql-contrib

# pgvector extension
sudo apt install postgresql-16-pgvector

# Ollama
curl -fsSL https://ollama.com/install.sh | sh
```

## 2ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/<your-repo>/smartwhatt-dsde-2025-project.git
cd smartwhatt-dsde-2025-project
```

## 3ï¸âƒ£ Create a Virtual Environment

```bash
uv venv
source .venv/bin/activate
uv sync
```

## 4ï¸âƒ£ Configure .env

Create a file in project root:

```properties
CONN_STRING=postgresql://postgres:YOUR_PASSWORD@localhost:5432/dsde
```

## 5ï¸âƒ£ Setup PostgreSQL Database

Create DB
```bash
sudo -u postgres psql
CREATE DATABASE dsde;
\c dsde;
```
Enable pgvector
```sql
CREATE EXTENSION vector;
```

Load schema
```bash
psql -U postgres -d dsde -f initialize_table.sql
```

## 6ï¸âƒ£ Install Ollama Models

```bash
ollama pull nomic-embed-text
ollama pull qwen2.5:7b
```

## 7ï¸âƒ£ Preprocessing Pipeline (Correct CLI Examples)

This project includes **three preprocessing stages**, and **each script uses argparse**, so you must run them with the correct flags.

Below are the **exact, correct commands** based on the real argparse definitions from your project files.

---

âœ… Step 1 â€” Convert JSON â†’ CSV  
**Script:** `processing/json_to_csv.py`  
**Source:** uses argparse with:  
- `--data-dir` (path to JSON files)  
- `--output-dir` (where CSVs will be created)  
- `--batch-size` (papers per batch)

```bash
python processing/json_to_csv.py \
    --data-dir ./processing/data \
    --output-dir ./csv_output \
    --batch-size 100
```

âœ… Step 2 â€” Load CSVs into PostgreSQL

**Script**: `processing/load_csv_to_db.py`
**Source**: argparse in the script provides:

- --csv-dir (directory containing CSV files)

- --clear (optional flag to truncate tables first)

```bash
python processing/load_csv_to_db.py \
    --csv-dir ./csv_output \
    --clear
```

âœ… Step 3 â€” Generate Paper Embeddings

**Script**: `processing/calculate_embedding_to_db.py`
**Source**: does not use argparse, runs immediately.

```bash
python processing/calculate_embedding_to_db.py
```


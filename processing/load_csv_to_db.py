"""Load CSV files into PostgreSQL database.

This script loads CSV files (generated by upload_data.py) into a PostgreSQL database.
"""

import argparse
import asyncio
import pathlib
import dotenv

from csv_to_db_loader import CSVToDBLoader, AsyncCSVToDBLoader

dotenv.load_dotenv(".env")


def load_csvs_to_database(csv_dir: pathlib.Path, conn_string: str):
    """Load CSV files into database synchronously.

    Args:
        csv_dir: Directory containing CSV files
        conn_string: PostgreSQL connection string
    """
    print(f"Loading CSV files from {csv_dir} into database")

    loader = CSVToDBLoader(conn_string=conn_string)
    try:
        results = loader.load_csv_directory(
            str(csv_dir),
            commit=True,
            progress_callback=lambda table, count: print(
                f"  → {table}: {count:,} rows"
            ),
        )

        print("\n" + "=" * 60)
        print("Summary:")
        print("=" * 60)
        total_rows = 0
        for table, count in results.items():
            print(f"  {table:30s} {count:>10,} rows")
            total_rows += count
        print("=" * 60)
        print(f"  {'TOTAL':30s} {total_rows:>10,} rows")
        print("=" * 60)

    finally:
        loader.close()


async def load_csvs_to_database_async(csv_dir: pathlib.Path, conn_string: str):
    """Load CSV files into database asynchronously.

    Args:
        csv_dir: Directory containing CSV files
        conn_string: PostgreSQL connection string
    """
    print(f"Loading CSV files from {csv_dir} into database (async)")

    async_loader = AsyncCSVToDBLoader(conn_string=conn_string, max_workers=1)
    try:
        results = await async_loader.load_csv_directory_async(
            str(csv_dir),
            commit=True,
            progress_callback=lambda table, count: print(
                f"  → {table}: {count:,} rows"
            ),
        )

        print("\n" + "=" * 60)
        print("Summary:")
        print("=" * 60)
        total_rows = 0
        for table, count in results.items():
            print(f"  {table:30s} {count:>10,} rows")
            total_rows += count
        print("=" * 60)
        print(f"  {'TOTAL':30s} {total_rows:>10,} rows")
        print("=" * 60)

    finally:
        await async_loader.close()


def main():
    parser = argparse.ArgumentParser(
        description="Load CSV files into PostgreSQL database"
    )
    parser.add_argument(
        "--csv-dir",
        type=pathlib.Path,
        default=pathlib.Path("./csv_output"),
        help="Directory containing CSV files (default: ./csv_output)",
    )
    parser.add_argument(
        "--async",
        dest="use_async",
        action="store_true",
        help="Use async loading (default: synchronous)",
    )

    args = parser.parse_args()

    # Validate CSV directory exists
    if not args.csv_dir.exists():
        print(f"Error: CSV directory {args.csv_dir} does not exist")
        return

    # Get connection string from environment
    conn_string = dotenv.get_key(".env", "CONN_STRING")
    if not conn_string:
        print("Error: CONN_STRING not found in .env file")
        return

    # Load CSVs
    if args.use_async:
        asyncio.run(load_csvs_to_database_async(args.csv_dir, conn_string))
    else:
        load_csvs_to_database(args.csv_dir, conn_string)


if __name__ == "__main__":
    main()
